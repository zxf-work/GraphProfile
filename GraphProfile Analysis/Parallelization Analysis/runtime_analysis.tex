\documentclass[12pt]{article}

\usepackage{fullpage,url,amssymb,epsfig,color,xspace,tikz,tikz-qtree, amsmath, pgfplots, multicol}
\usetikzlibrary{positioning}
%\usepackage{algpseudocode}
%\usepackage{algorithmicx}
\usepackage{hyperref}
\RequirePackage{pstricks,pst-node,pst-tree} % draw trees, requires using xetex
\newlength{\nodeLength}
\newcommand{\Node}{A}
\newcommand{\setnode}[1]{
  \settowidth{\nodeLength}{#1}
  \renewcommand{\Node}[1]{
    \Tcircle[name=#1]{\makebox[\nodeLength]{##1}}
  }
}
\setnode{99}

\begin{document}

\begin{center}
{\Large\bf Performance of Parallel Graph Profiling Algorithms}\\
\end{center}

\section{Introduction}

This article will be examining how parallelization and multithreading techniques affect the runtime of graph profiling and reduction algorithms. Using Intel's Thread Building Blocks (TBB) Library, we can use high level parallel algorithms and data structures to take full advantage of multicore performance, and optimize computationally heavy, long running code.

\section{Algorithms}

This article focuses on parallelizing several graph profiling algorithms. The algorithms considered are:

\begin{itemize}
  \item abc: approximate betweenness centrality of a vertex - approximation of the number of shortest paths from all vertices to all others that pass through the node
  \item adiam: approximate diameter - approximation of the longest shortest path in the graph
  \item aprank: approximate page rank of the vertices of a graph
  \item bc: betweenness centrality of all vertices in a graph
  \item cc: connected components - the number of connected components and their sizes
  \item etri: exact triangle count - the number of triangles in a graph
  \item lcc: average local clustering coefficient - degree of which nodes in a graph tend to cluster together
  \item prank: page rank of the vertices of a graph
\end{itemize}

In addition, several graph reduction algorithms are also analyzed:
\begin{itemize}
  \item reduce: create a reduced graph by keeping the top x neighbors of each vertex, ordered by their degree
  \item reducetri: similar to reduce, but avoiding triangles when possible
  \item reducetreetop: create a reduced graph from the spanning trees of the top x vertices, ordered by their degree
  \item reducehighdegreetop: similar to reducetreetop, but using a different BFS algorithm
  \item reducepercent: create a reduced graph by keeping the top x\% of vertices past the median degree of all vertices
\end{itemize}

\section{Parallelization Techniques}

TBB provides several high level parallel functions and data structures that can be used. This section highlights how some of these tools were used.

Parallel Functions:
\begin{itemize}
  \item parallel\_for

  Most commonly used loop - performs parallel iteration over a range of values, which can be specified with a start and end value, or with a blocked\_range object.

  Useful for: 

  \begin{itemize}
    \item repeatedly performing a calculation for an approximation (e.g. repeatedly selecting a vertex and computing a dependency score to calculate an approximate betweeness centrality)
    \item performing an operation on every element of an array (e.g. calculating the page rank for each vertex, calculating heuristics for graph reduction algorithms)
    \item optimizing doubly or triply nested for loops when used in conjunction with blocked\_range2d or blocked\_range3d (e.g. when counting triangles, or calculating betweenness centrality of every vertex)
  \end{itemize}

  \item parallel\_for\_each

  Performs parallel iteration over sequences that do not have random access (for example, lists), at the cost of additional overhead. The sequence is specified with iterators pointing to the start and end of the range of the range to iterate over.

  It is useful as many functions in the boost graph library used by this project returns lists. For example, \texttt{boost::adjacent\_vertices} returns a pair of iterators to a list of vertices adjacent to a specified vertex, and is used in calculating betweenness centrality, clustering coefficients, connected components, spanning trees, triangle counts, and graph reductions.

  It is important to note that parallel\_for\_each comes with significant overhead. Intel's documentation suggests that "For good performance with input streams that do not have random access, execution of B::operator() should take at least ~100,000 clock cycles. If it is less, overhead of parallel\_for\_each may outweigh performance benefits."

  \item parallel\_reduce

  Computes a reduction over a range - for example finding the sum of an array. It works by first recursively splitting the range into subranges, performing the body operation (specified by the user) on each of these ranges, and then joining these ranges together (how these values are joined together is also specified by the user).

  It is used over, say, a parallel\_for loop, as a parallel\_for loop may end up having multiple threads writing to the same variable (in this case, the running sum, or value being aggregated from the range) at the same time, or overwriting each other, leading to innaccurate results or segmentation faults. If a mutex is used in a parallel\_for loop to protect the variable, then runtime is slowed down, and in worst case, the loop becomes serial.

  In this project, it is used to calculate the number of triangles and clustering coefficient.

  \item parallel\_do

  Function that processes work items in parallel, in which new items can be added as current items are processed by using the parallel\_do\_feeder classes. Similar to parallel\_for\_each, it comes with additional overhead. 

  Used in parallel bfs algorithm - unvisited neighbors of visited vertices are added to a queue, as the parallel\_do loop searches through the queue in parallel.

  \item parallel\_sort

  Sorts a sequence or a container in parallel, in a non stable, non deterministic fashion. Used in graph reduction algorithms, where vertices are sorted by their degree.

  \item blocked\_range, blocked\_range2d, blocked\_range3d

  blocked\_range is not a function, but rather an object that can be used to represent a range of values to iterate over. When used in conjunction with parallel\_for, or parallel\_reduce, it splits itself into multiple, smaller blocked ranges, which can be iterated over serially in seperate threads.

  Using blocked ranges can help optimize code, as it allows the user to specify an optimal grain size for the smaller blocked ranges to improve runtime, and also lets the user write optimized nested for loops without having to nest parallel\_for or parallel\_reduce functions.

\end{itemize}

Concurrent Data Structures:
\begin{itemize}
  \item concurrent\_vector

  Template class for a vector that can be concurrently grown and accessed (i.e. multiple threads can append elements and access elements at the same time). 

  Useful for calculating and creating the edges for a reduced graph in parallel, as many edges can be calculated in parallel, and added to the vector.

  \item concurrent\_unordered\_map, concurrent\_unordered\_multimap

  Template classes that support concurrent insertion and traversal, but not concurrent erasure. 

  concurrent\_unordered\_map is used to store heuristics about vertices while an algorithm is runnning - for example, the "priority" of a vertex during graph reduction, and whether or not a vertex has been visited in BFS.

  concurrent\_unordered\_multimap is to create and store spanning minimum spanning trees to perform graph reductions on.

\end{itemize}

\section{Data Collection}

Runtimes of each algorithm was measured using the \texttt{<time.h>} library provided by C, and is calculated as the difference between before the function was called and after, rounded to the nearest second. In the future, the \texttt{<chrono>} library can be used instead, to get a time difference in milliseconds, for more accurate results. See \url{https://stackoverflow.com/questions/31487876/getting-a-time-difference-in-milliseconds} for details.

The parallelizeed and unparallelized versions of each algorithm were run 5 times each, on 6 different graphs with a varying number of vertices, edges, and density. The program was run on the waterloo student linux environment, on which 56-64 threads were consistently available. The runtimes were recorded, and averages were used for analysis.


\begin{tabular}{|l|l|l|l|l}
\cline{1-4}
\hline
Graph Name          & Num. Edges  & Num. Vertices & Average Degree \\
\hline
5.txt                  & 5      & 6        & 1.666667        \\
\hline
50.txt                 & 50     & 51       & 1.960784        \\
\hline
small\_test.txt        & 55     & 1904     & 0.057773        \\
\hline
facebook\_combined.txt & 88234  & 4039     & 43.69101        \\
\hline
enron.txt              & 367662 & 36692    & 20.04044        \\
\hline
epinions.txt           & 508837 & 75888    & 13.41021        \\
\hline
\end{tabular}

\section{Results}

The average runtimes and standard deviations for each algorithm are shown below, plotted against the number of edges in each graph.

\begin{multicols}{2}

  \begin{tikzpicture}
  \begin{axis}[
  title={abc},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =abc_seq_time, y error =abc_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =abc_tbb_time, y error =abc_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={adiam},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =adiam_seq_time, y error =adiam_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =adiam_tbb_time, y error =adiam_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={aprank},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =aprank_seq_time, y error =aprank_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =aprank_tbb_time, y error =aprank_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={bc},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =bc_seq_time, y error =bc_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =bc_tbb_time, y error =bc_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}

  \begin{tikzpicture}
  \begin{axis}[
  title={cc},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =cc_seq_time, y error =cc_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =cc_tbb_time, y error =cc_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={etri},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =etri_seq_time, y error =etri_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =etri_tbb_time, y error =etri_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={lcc},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =lcc_seq_time, y error =lcc_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =lcc_tbb_time, y error =lcc_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={prank},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =prank_seq_time, y error =prank_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =prank_tbb_time, y error =prank_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={reduce},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reduce_seq_time, y error =reduce_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reduce_tbb_time, y error =reduce_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={reducetri},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducetri_seq_time, y error =reducetri_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducetri_tbb_time, y error =reducetri_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={reducetreetop},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducetreetop_seq_time, y error =reducetreetop_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducetreetop_tbb_time, y error =reducetreetop_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={reducehighdegreetop},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducehighdegreetop_seq_time, y error =reducehighdegreetop_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducehighdegreetop_tbb_time, y error =reducehighdegreetop_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}


  \begin{tikzpicture}
  \begin{axis}[
  title={reducepercent},
  xlabel={Number of edges},
  ylabel={Runtime (s)},
  xmin=0,
  ymin=0,
  legend pos=north west,
  width=200 pt
  ]
  \addplot [color=blue, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducepercent_seq_time, y error =reducepercent_seq_err, col sep=comma]{runtime_data_clean.csv}
   ;
  \addplot [color=red, mark=o,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =edges, y =reducepercent_tbb_time, y error =reducepercent_tbb_err, col sep=comma]{runtime_data_clean.csv}
   ;
   \legend{Unparallelized, Parallelized}
  \end{axis}
  \end{tikzpicture}
\end{multicols}

Some notes:


Betweeness Centrality is highly RAM intensive, and often crashes on larger graphs. 
\section{Analysis}


  \begin{tikzpicture}
  \begin{axis}[
  xbar, 
  xmin=0,
  title={\# Times Runtime Speedup, by Command},
  xlabel={Average \# Times Speedup},  
  symbolic y coords={cc, reducepercent, reduce, reducetreetop, reducehighdegreetop, prank, lcc, reducetri, etri, abc, bc, aprank, adiam},
  width=350 pt,
  height=275 pt,
  ytick=data
  ]
  \addplot [fill=blue,]
   plot [error bars/.cd, x dir = both, x explicit]
   table[x =improvement, x error =stdev, y =command, col sep=comma]{improvement_by_command.csv}
   ;
  \end{axis}
  \end{tikzpicture}

  \begin{tikzpicture}
  \begin{axis}[
  ybar, 
  title={\# Times Runtime Speedup, by Graph Size},
  xlabel={\# Vertices in Graph},
  ylabel={Average \# Times Speedup},  
  width=350 pt,
  height=275 pt,
  ymin=0,
  xtick=data,
  symbolic x coords={6, 51, 1904, 4039, 36692, 75888}
  ]
  \addplot [fill=blue,]
   plot [error bars/.cd, y dir = both, y explicit]
   table[x =vertices, y =improvement, y error =stdev, col sep=comma]{improvement_by_graph.csv}
   ;
  \end{axis}
  \end{tikzpicture}

\end{document}
